# Implementation Plan: Optimize Lichess API Queue

## 1. Context & Goal
The current Lichess enrichment is slow because it processes requests sequentially (1 per second) and re-fetches the same FEN multiple times for transposed lines.
We will implement **In-Flight Deduplication** to prevent redundant network calls for identical positions, and **Burst Concurrency** to fetch small batches (3 requests) in parallel, significantly increasing throughput while respecting rate limits.

## 2. Memory Update
Refactoring `src/background/index.ts` to use a batched queue processor (`BATCH_SIZE=3`) and a `Promise` map for request deduplication. Removing internal function throttling in favor of batch-level timing.

## 3. Step-by-Step Instructions

### Step 1: Add Deduplication State
**Action:** Modify `src/background/index.ts`
**Description:**
- Add `const activeFetches = new Map<string, Promise<LichessStats | undefined>>();` to track pending API calls.
- Remove `lastLichessRequest` and `LICHESS_RATE_LIMIT_MS` (logic moves to the queue processor).

### Step 2: Refactor `getLichessStats`
**Action:** Modify `src/background/index.ts`
**Description:**
- Remove the internal `setTimeout` throttling.
- **Implement Deduplication:**
    - Check `activeFetches.has(fen)`. If yes, return the existing promise.
    - If no, create a new fetch promise.
    - Store promise in `activeFetches`.
    - Add a `.finally()` block to the promise to remove the FEN from `activeFetches` when done.
- **Error Handling:** If response is `429`, throw a specific error so the queue manager knows to back off.

### Step 3: Implement Burst Queue Processor
**Action:** Modify `src/background/index.ts`
**Description:**
- **Constants:** Set `BATCH_SIZE = 3` and `BATCH_DELAY_MS = 2000` (Effective rate ~1.5 req/sec, but pipelined).
- **Refactor `processQueue`:**
    - Loop while `enrichmentQueue` is not empty.
    - Splice `BATCH_SIZE` items from the queue.
    - Run them in parallel: `await Promise.all(batch.map(processItem))`.
    - Measure elapsed time.
    - `await sleep(Math.max(0, BATCH_DELAY_MS - elapsed))`.
- **429 Handling:** Wrap the batch processing in a try/catch. If a Rate Limit error occurs:
    - Log a warning.
    - Put the batch items back into the queue (`unshift`).
    - Wait 60 seconds (`await sleep(60000)`).

## 4. Verification
1.  Run `npm run build`.
2.  Reload Extension.
3.  **Test:** Start Extraction on a large course (e.g., Vienna).
4.  **Observe:**
    - Dashboard rows should update in "clumps" of 3 rather than 1-by-1.
    - Network tab (Background DevTools) should show 3 concurrent requests, then a pause.
    - "Transpositions" (same position reached via different moves) should happen instantly without network calls (Deduplication).
